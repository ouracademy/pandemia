# -*- coding: utf-8 -*-
# """HIBRIDO7a1_1ArabiaSaudita_Clas.ipynb

# Automatically generated by Colab.

# Original file is located at
#     https://colab.research.google.com/drive/1XU6SnmzokHJYFFc1M7LRHKcyM_v36RmK

# ALGORITMO HIBRIDO 7: RF, SVM, GBM, NB, DT, XGBOOST, LogR.
# Ensemble con LSTM.  y luego con SVM  por separado
# """

# !pip install https://bit.ly/3o4smsZ

import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score, roc_curve, auc, accuracy_score, precision_score, recall_score, f1_score, mean_squared_error #, confusion_matrix, classification_report
from sklearn.model_selection import train_test_split
import xgboost as xgb
from sklearn.naive_bayes import GaussianNB
from sklearn.preprocessing import label_binarize


data = pd.read_csv("/content/drive/MyDrive/Desarrollo/DataPorPais/daily_cases_ksa_covid19ArabiaSauditaDepuradoEncoded.csv",sep=",")

data['Confirmed_entero'] = data['Confirmed'].astype(int)

# Cargar un conjunto de datos de ejemplo
# Dividir el conjunto de datos en características (X) y etiquetas (y)
X = data.drop('Confirmed_entero', axis=1)
y = data['Confirmed_entero']

# Dividir el conjunto de datos en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Entrenar modelos individuales
rf_model = RandomForestClassifier()
rf_model.fit(X_train, y_train)

svm_model = SVC()
svm_model.fit(X_train, y_train)

gbm_model = GradientBoostingClassifier()
gbm_model.fit(X_train, y_train)

naive_bayes = GaussianNB()
naive_bayes.fit(X_train, y_train)

dt_model = DecisionTreeClassifier()
dt_model.fit(X_train, y_train)

unique_classes = np.unique(y_train)
print("Clases únicas en y_train:", unique_classes)
# Obtener un mapeo de las clases originales a las nuevas clases consecutivas

class_mapping = {original_class: new_class for new_class, original_class in enumerate(unique_classes)}
# Aplicar el mapeo a las etiquetas de entrenamiento
y_train_consecutive = np.array([class_mapping[cls] for cls in y_train])
#Utilizar y_train_consecutive en lugar de y_train para entrenar el modelo:
xgb_model = xgb.XGBClassifier()
xgb_model.fit(X_train, y_train_consecutive)

lr_model = LogisticRegression(max_iter=10000)
lr_model.fit(X_train, y_train)

# Realizar predicciones
rf_predictions = rf_model.predict(X_test)
svm_predictions = svm_model.predict(X_test)
gbm_predictions = gbm_model.predict(X_test)
nb_predictions = naive_bayes.predict(X_test)
dt_predictions = dt_model.predict(X_test)
xgb_predictions = xgb_model.predict(X_test)
lr_predictions = lr_model.predict(X_test)

#Se utiliza las salidas de los 7 algoritmos  como entrada para un clasificador SVM
svm_input = np.column_stack((rf_predictions.reshape(-1, 1), svm_predictions.reshape(-1, 1), gbm_predictions.reshape(-1, 1),
                               nb_predictions.reshape(-1, 1), dt_predictions.reshape(-1, 1),
                               xgb_predictions.reshape(-1, 1),lr_predictions.reshape(-1, 1)))
svm_classifier = SVC(kernel='linear', probability=True)  # Puedes ajustar el kernel según tus necesidades
svm_classifier.fit(svm_input, y_test)

# Hacer predicciones con el clasificador SVM
svm_predictions = svm_classifier.predict(svm_input)

#Obtener probabilidades predichas usando 'predict_proba'
# y_probs = svm_classifier.predict_proba(svm_input)

# Calcular las métricas de evaluación
# auc = roc_auc_score(y_test, y_probs, multi_class='ovr')
# precision = precision_score(y_test, svm_predictions, average='macro')
# accuracy = accuracy_score(y_test, svm_predictions)
# f1 = f1_score(y_test, svm_predictions, average='macro')
# recall = recall_score(y_test, svm_predictions,average='macro')
# mse = mean_squared_error(y_test, svm_predictions)
# rmse = mse ** 0.5

# Imprimir los resultados
# print("Métricas de evaluación:")
# print("AUC:", auc)
# print("Precision:", precision)
# print("Accuracy:", accuracy)
# print("F1 score:", f1)
# print("Recall:", recall)
# print("MSE:", mse)
# print("RMSE:", rmse)

# Binarizar la salida
# y_test_bin = label_binarize(y_test, classes=np.unique(svm_predictions))
# n_classes = y_test_bin.shape[1]

# Calcular la curva ROC y el área ROC para cada clase
# fpr = dict()
# tpr = dict()
# roc_auc = dict()
# for i in range(n_classes):
#     fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_probs[:, i])
#     roc_auc[i] = auc(fpr[i], tpr[i])

# Calcular la curva ROC micropromedio y el área ROC
# fpr["micro"], tpr["micro"], _ = roc_curve(y_test_bin.ravel(), y_probs.ravel())
# roc_auc["micro"] = auc(fpr["micro"], tpr["micro"])
